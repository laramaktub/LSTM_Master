{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generación de textos con una LSTM\n",
    "\n",
    "Vamos a implementar una LSTM en Keras. Lo primero que necesitamos es gran cantidad de texto para poder aprender un modelo de lingüistica. Se puede usar cualquier archivo grande de texto. En este ejemplo vamos a usar El Quijote. Nuestro modelo aprenderá así un modelo específico basado en el estilo de escritura de Cervantes en ese libro concreto. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando los datos\n",
    "\n",
    "Lo primero que hacemos es descargar el corpus y pasarlo todo a minúsculas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "\n",
    "path = keras.utils.get_file(\n",
    "    'quijote.txt',\n",
    "    origin='https://gist.githubusercontent.com/jsdario/6d6c69398cb0c73111e49f1218960f79/raw/8d4fc4548d437e2a7203a5aeeace5477f598827d/el_quijote.txt')\n",
    "text = open(path).read().lower()\n",
    "print('Longitud del corpus:', len(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "A continuación extraeremos frases que tengan un solapamiento parcial de longitud `maxlon`, las convertiremos en un vector one-hot, y las meteremos en un array 3D de Numpy `x` cuya estructura corresponda a `(n_frases, maxlon, caracteres_unicos)`. Simultaneamente prepararemos un array `y` que contenga los targets correspondientes: los vectores one-hot de los caracteres que vienen justo después de cada frase extraida. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Length of extracted character sequences\n",
    "maxlon = 60\n",
    "\n",
    "# We sample a new sequence every `step` characters\n",
    "step = 3\n",
    "\n",
    "# This holds our extracted sequences\n",
    "sentences = []\n",
    "\n",
    "# This holds the targets (the follow-up characters)\n",
    "next_chars = []\n",
    "\n",
    "for i in range(0, len(text) - maxlon, step):\n",
    "    sentences.append(text[i: i + maxlon])\n",
    "    next_chars.append(text[i + maxlon])\n",
    "print('Número de frases:', len(sentences))\n",
    "\n",
    "# List of unique characters in the corpus\n",
    "chars = sorted(list(set(text)))\n",
    "print('Caracteres únicos:', len(chars))\n",
    "# Dictionary mapping unique characters to their index in `chars`\n",
    "char_indices = dict((char, chars.index(char)) for char in chars)\n",
    "\n",
    "# Next, one-hot encode the characters into binary arrays.\n",
    "print('Vectorización...')\n",
    "x = np.zeros((len(sentences), maxlon, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construyendo la red\n",
    "\n",
    "Nuestra red no es mas que una única capa `LSTM` seguida por un clasificador `Denso` y un softmax sobre todos los posibles caracteres. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(layers.LSTM(128, input_shape=(maxlon, len(chars))))\n",
    "model.add(layers.Dense(len(chars), activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como nuestros targets son vectores one-hot, usaremos `categorical_crossentropy` como función de pérdida de nuestro modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.RMSprop(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenando el modelo lingüistico y sampleando a partir de él\n",
    "\n",
    "\n",
    "Dado un modelo entrenado y un fragmento de texto como semilla, generaremos un nuevo texto siguiendo reiteradamente estos pasos: \n",
    "\n",
    "*  Extraer a partir del modelo la distribución de probabilidad para el texto dado hasta ese momento.\n",
    "*  Repesar la distribución para una cierta \"temperatura\"\n",
    "*  Samplear el siguiente caracter aleatoriamente de acuerdo a la distribución repesada\n",
    "*  Añadir ese caracter al final del texto disponible.\n",
    "\n",
    "Con este codigo repesamos la probabilidad original que viene del modelo y extraemos un indice de caracteres (función de \"sampleo\"):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperatura=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperatura\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, aqui tenemos el bucle en el entrenaremos y generaremos el texto. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import sys\n",
    "\n",
    "for epoch in range(1, 20):\n",
    "    print('Época: ', epoch)\n",
    "    # Fit the model for 1 epoch on the available training data\n",
    "    model.fit(x, y,\n",
    "              batch_size=128,\n",
    "              epochs=1)\n",
    "\n",
    "    # Select a text seed at random\n",
    "    start_index = random.randint(0, len(text) - maxlon - 1)\n",
    "    generated_text = text[start_index: start_index + maxlon]\n",
    "    print('--- Generando con la siguiente semilla: \"' + generated_text + '\"')\n",
    "\n",
    "    for temperatura in [0.3]:\n",
    "        print('------ Temperatura:', temperatura)\n",
    "        sys.stdout.write(generated_text)\n",
    "\n",
    "        # We generate 400 characters\n",
    "        for i in range(400):\n",
    "            sampled = np.zeros((1, maxlon, len(chars)))\n",
    "            for t, char in enumerate(generated_text):\n",
    "                sampled[0, t, char_indices[char]] = 1.\n",
    "\n",
    "            preds = model.predict(sampled, verbose=0)[0]\n",
    "            next_index = sample(preds, temperatura)\n",
    "            next_char = chars[next_index]\n",
    "\n",
    "            generated_text += next_char\n",
    "            generated_text = generated_text[1:]\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Tareas\n",
    "\n",
    "*  Utiliza tu propio corpus en lugar de El Quijote (puede ser en otros idiomas)\n",
    "*  Modifica el bucle para que recorra varias temperaturas a cada vez (entre 0.1 y 1 por ejemplo), de modo que podamos ir comparando para cada época que aspecto tiene el texto resultante dependiendo de dicha temperatura.\n",
    "*  Entrena para 60 epocas.\n",
    "*  ¿Qué observas en el texto según vas variando la temperatura? ¿Cuál te parece la temperatura óptima y por qué?\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
